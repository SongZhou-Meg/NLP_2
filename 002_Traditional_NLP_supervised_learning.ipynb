{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = r'C:\\Users\\86138\\Desktop\\Techlent\\week15\\sentiment.csv'\n",
    "df = pd.read_csv(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                             review\n",
       "0          1  With all this stuff going down at the moment w...\n",
       "1          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2          0  The film starts with a manager (Nicholas Bell)...\n",
       "3          0  It must be assumed that those who praised this...\n",
       "4          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"review\"] # Note that it is a Series rather than a DataFrame here\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='sentiment'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y.value_counts().plot(kind='pie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After vectorizing texts, you can use any ML algorithm to build a NLP classifier. But keep in mind that there is a huge number of features in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_tokenizer(text):\n",
    "    stemmer = EnglishStemmer(ignore_stopwords=True)\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", text).lower().split()\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    return words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=stopwords.words('english'),\n",
    "                        tokenizer=stem_tokenizer,\n",
    "                        lowercase=True,\n",
    "                        max_df=0.5,\n",
    "                        min_df=5,\n",
    "                        ngram_range=(1, 3)\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgclassifier = Pipeline([('tfidf', tfidf), ('lg', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgclassifier = lgclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.84       716\n",
      "           1       0.85      0.88      0.86       784\n",
      "\n",
      "    accuracy                           0.85      1500\n",
      "   macro avg       0.85      0.85      0.85      1500\n",
      "weighted avg       0.85      0.85      0.85      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, lgclassifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: Get the most important grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "grams = [''] * len(lgclassifier['tfidf'].vocabulary_)\n",
    "for k, v in lgclassifier['tfidf'].vocabulary_.items():\n",
    "    grams[v] = k\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gram_weight = list(zip(grams, lgclassifier['lg'].coef_[0]))\n",
    "gram_weight.sort(key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bad', -5.088262361964956),\n",
       " ('worst', -3.546877610840104),\n",
       " ('wast', -3.0172729746229985),\n",
       " ('poor', -2.9718451865933115),\n",
       " ('aw', -2.635037401092495)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram_weight[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('best', 2.059697814633336),\n",
       " ('perfect', 2.3233155440390347),\n",
       " ('excel', 2.4377771977149068),\n",
       " ('love', 3.0990176525314324),\n",
       " ('great', 3.9504520717052394)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram_weight[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words=stopwords.words('english'),\n",
    "                     tokenizer=stem_tokenizer,\n",
    "                     lowercase=True,\n",
    "                     max_df=0.5,\n",
    "                     min_df=5,\n",
    "                     ngram_range=(1, 3),\n",
    "                     binary=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbclassifier = Pipeline([('cv', cv), ('nb', BernoulliNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbclassifier = nbclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       716\n",
      "           1       0.85      0.87      0.86       784\n",
      "\n",
      "    accuracy                           0.85      1500\n",
      "   macro avg       0.85      0.85      0.85      1500\n",
      "weighted avg       0.85      0.85      0.85      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, nbclassifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> Why Naive Bayes is Naive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> What are the pros and cons of Naive Bayes models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> We use BernoulliNB here. What are the other Naive Bayes models? What are the differences? Why do we need to set \"binary=True\" in Countvectorizer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If True, all non zero counts are set to 1. This is useful for discrete probabilistic models that model binary events rather than integer counts.\n",
    "\n",
    "#### When binary = True, we will perform one hot encoding of the given data.\n",
    "\n",
    "#### When binary = False, we will calculate frequency of the given data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: Get the most important grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 14726)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbclassifier['nb'].feature_log_prob_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('watch', -0.9443808562264415),\n",
       " ('good', -0.9313842833992609),\n",
       " ('time', -0.925661807125195),\n",
       " ('make', -0.9199718913475161),\n",
       " ('even', -0.9030938535601649)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_weight = list(zip(grams, nbclassifier['nb'].feature_log_prob_[0]))\n",
    "pos_weight.sort(key=lambda x: x[1])\n",
    "pos_weight[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('stori', -1.0485878104147925),\n",
       " ('make', -1.008292270236784),\n",
       " ('see', -0.9695577610556425),\n",
       " ('good', -0.9559726464653364),\n",
       " ('time', -0.8426975072481424)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_weight = list(zip(grams, nbclassifier['nb'].feature_log_prob_[1]))\n",
    "neg_weight.sort(key=lambda x: x[1])\n",
    "neg_weight[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> How **feature_log_prob_** is calculated? Any way to improve it? My solution is in this article (https://www.linkedin.com/pulse/rescale-amazon-ratings-using-reviews-guo-li/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
